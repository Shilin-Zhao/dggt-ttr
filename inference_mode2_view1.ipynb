{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cae861-85c4-4c5c-99a3-c0327b277b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 1. System & Path Setup\n",
    "# -----------------------------------------------------------------------------\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['HF_HUB_OFFLINE'] = '1'\n",
    "os.environ['HF_HOME'] = os.path.expanduser('~/.cache/huggingface')\n",
    "print(\"Hugging Face offline mode enabled.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. Project Imports \n",
    "# -----------------------------------------------------------------------------\n",
    "from core_pipeline import *\n",
    "from vis_utils import *\n",
    "from datasets.dataset import WaymoOpenDataset\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. Environment Check\n",
    "# -----------------------------------------------------------------------------\n",
    "%matplotlib inline\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Environment ready. Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47e2847-af3a-4ce6-932b-9d888ab69477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 实例化 Config (对应你提供的命令行参数)\n",
    "# -----------------------------------------------------------------------------\n",
    "scene_names = [\"000\"]\n",
    "input_views = 1\n",
    "squence_length = 20\n",
    "start_idx=0\n",
    "force_refresh = False\n",
    "# output_path=f\"outputs/scene{scene_name}_start{start_idx}_len{squence_length}_view{input_views}\"\n",
    "output_path=\"baseline\"\n",
    "\n",
    "config = DGGTConfig(\n",
    "    # 必需路径参数\n",
    "    image_dir=\"data/waymo/processed/validation\",\n",
    "    ckpt_path=\"/root/pretrained/model_latest_waymo.pt\", \n",
    "    output_path=output_path,\n",
    "    \n",
    "    # 场景设置\n",
    "    scene_names=scene_names,       # --scene_name 000\n",
    "    input_views=input_views,             # --input_views 1\n",
    "    sequence_length=squence_length,        # --sequence_length 20\n",
    "    start_idx=start_idx,               # --start_idx 0\n",
    "    \n",
    "    # 功能开关 (根据你的命令行: -images -metrics -diffusion)\n",
    "    images=True,\n",
    "    metrics=True,\n",
    "    \n",
    "    # Refinement 开关 (命令行未开启，设为False，后续调试可改为True)\n",
    "    enable_refinement=False,   \n",
    "    depth=True\n",
    ")\n",
    "\n",
    "print(f\"Config loaded for scenes: {config.scene_names}\")\n",
    "print(f\"Output path: {config.output_path}\")\n",
    "print(f\"Refinement enabled: {config.enable_refinement}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e244b2ab-d17e-41e4-8f27-b3f9d52b3dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化 Dataset\n",
    "# 假设 datasets.dataset 已经可以 import 并且包含了你提供的逻辑\n",
    "# 如果是在 autodl 本地文件，确保路径正确\n",
    "dataset = WaymoOpenDataset(\n",
    "    image_dir=config.image_dir,\n",
    "    scene_names=scene_names,\n",
    "    sequence_length=config.sequence_length,\n",
    "    start_idx=config.start_idx,\n",
    "    mode=2,             # pure reconstruction\n",
    "    views=config.input_views\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1388ed-7d7f-464c-b253-e3a3b297ceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行可视化\n",
    "visualize_samples(dataset, [0, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07363a-da61-47be-9c33-0081e67cecc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 4. Load Model, Run Inference & Visualize Results\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# A simple logger for notebook use\n",
    "class NotebookLogger:\n",
    "    def info(self, msg):\n",
    "        print(f\"[INFO] {msg}\")\n",
    "\n",
    "# 1. Setup Environment & Model\n",
    "logger = NotebookLogger()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Loading checkpoint from: {config.ckpt_path}\")\n",
    "model = load_model(config, device, logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7e6e7d-ffc0-4a77-affb-199ede87816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting depth data...\")\n",
    "dggt_depth, dggt_sky, da3_depth, da3_sky = extract_depth_alignment_data(config, model, dataset, device)\n",
    "\n",
    "run_depth_alignment_debug(\n",
    "    sample_indices=[0, 4],\n",
    "    dggt_depth_seq=dggt_depth,\n",
    "    dggt_sky_seq=dggt_sky,\n",
    "    da3_depth_seq=da3_depth,\n",
    "    da3_sky_seq=da3_sky,\n",
    "    logger=logger,\n",
    "    visualize_func=visualize_depth_alignment_6panel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035acbc9-6d47-4568-b713-c75fefc783b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Run Inference\n",
    "# Ensure config matches your current memory constraints (seq_len=2)\n",
    "print(f\"Running inference for scene: {config.scene_names} (Seq Len: {config.sequence_length})...\")\n",
    "\n",
    "# results is a list of dicts (one per scene)\n",
    "config.diffusion =  True\n",
    "config.penalize_alphas = False\n",
    "config.use_nearest = True\n",
    "config.metrics = True\n",
    "config.enable_refinement = False\n",
    "config.refine_pose = False\n",
    "config.refine_gs = False\n",
    "config.enable_da3 = True\n",
    "results = run_inference_and_render(config, model, dataset, logger, device=device)\n",
    "scene_data = results[0] # Get first scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c38f2b-dd95-4a12-bad0-765ce05470a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Vis\n",
    "visualize_inference_results(scene_data,[0, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470e66f-6db5-48e3-9b92-648c75f704b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Usage Example ---\n",
    "# 假设 scene_data 已经由上面的推理代码生成\n",
    "# save_indices = [0] # 只要第一帧\n",
    "output_folder = \"outputs/debug/da3_nearest_diffusion\"\n",
    "\n",
    "save_visualization_results(scene_data, [0, 4], output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dggt",
   "language": "python",
   "name": "dggt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
